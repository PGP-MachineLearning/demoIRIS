{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DAE Imag IRIS.ipynb","provenance":[{"file_id":"1gEcMqfeYOJnjxHE-AACF0t8SJTXIsif6","timestamp":1580735169391}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"r6X3sZdb3I7T","colab_type":"text"},"source":["# Demo de Deep Autoencoder (DAE) para procesar las imágenes de tipos de Iris\n","Basado en: \n","\n","https://blog.keras.io/building-autoencoders-in-keras.html\n","\n","\n","https://towardsdatascience.com/deep-autoencoders-using-tensorflow-c68f075fd1a3"]},{"cell_type":"markdown","metadata":{"id":"ZQ3UDqAY4zlD","colab_type":"text"},"source":["1) Importar librerías:"]},{"cell_type":"code","metadata":{"id":"NafdiEwq3IMh","colab_type":"code","colab":{}},"source":["import keras\n","from keras.layers import Input, Dense\n","from keras.models import Model\n","from keras.utils import plot_model\n","\n","from sklearn.decomposition import PCA\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","import os\n","\n","from PIL import Image\n","\n","print(\"\\nLibrerías importadas\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TqJT-899FP7H","colab_type":"text"},"source":["2) Definir la configuración del modelo DAE:"]},{"cell_type":"code","metadata":{"id":"i2uoSF7XFQuS","colab_type":"code","colab":{}},"source":["# tamaño de las imágenes\n","IMAGE_SHAPE = (32, 32, 3)\n","\n","# cantidad de neuronas ocultas para features (datos comprimidos o codings)\n","num_features = 12\n","\n","# cantidad de neuronas ocultas para la parte Encoder \n","#   (cada elemento de la lista es la cantidad de pesos que tiene cada una)\n","dae_layers = [ 392, 196, 84, 56, 32 ] \n","\n","# define tamaño de datos de entrada y salida\n","num_inputs = IMAGE_SHAPE[0] * IMAGE_SHAPE[1] * IMAGE_SHAPE[2]\n","num_outputs = num_inputs\n","\n","#  agrega la capa de features a las capas\n","dae_layers.append( num_features ) \n","\n","# cantidad de neuronas ocultas para la parte Decoder \n","#   (usa la la lista de Encoder inversa)\n","for eachEncLayer in dae_layers[0:len(dae_layers)-1][::-1]:\n","  dae_layers.append( eachEncLayer )\n","\n","# cantidad de épocas del entrenamiento\n","# (a medida que la cantidad de capas ocultas se mayor y el nro de features es menor, \n","#   se recomienda entrenar más épocas)\n","cantEpocas = 500\n","\n","print(\"Configuración del DAE definida: [\", num_inputs, dae_layers, num_outputs, \"] \")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pgMOT8WvGWMB","colab_type":"text"},"source":["3) Montar el Drive:"]},{"cell_type":"code","metadata":{"id":"0pkkaUToGKc7","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","\n","# directorio local en Google Drive\n","path = 'gdrive/My Drive/IA/demo IRIS' \n","imagPath = path + '/IRIS/train' "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tMbKRc0E5ONE","colab_type":"text"},"source":["4) Cargar imágenes para entrenar el modelo DAE:"]},{"cell_type":"code","metadata":{"id":"GE_3cMSTyzfG","colab_type":"code","colab":{}},"source":["# cargar las imágenes\n","classes_ori = [] \n","images_ori = []\n","\n","all_dirs = os.listdir( imagPath )\n","for each_dir in all_dirs:\n","\n","    auxiPath = imagPath + '/' + each_dir \n","    imagFN  = os.listdir( auxiPath )\n","    for each_imagFN in imagFN:\n","          \n","          # abre la imagen\n","          imag = Image.open(auxiPath + \"/\" + each_imagFN)\n","          \n","          # ajusta el tamaño\n","          if IMAGE_SHAPE[2]==1:\n","            imag = imag.convert('L')\n","            tipoImage = 'L'\n","          else:\n","            tipoImage = 'RGB'\n","          imag = imag.resize((IMAGE_SHAPE[0], IMAGE_SHAPE[1]), Image.ANTIALIAS)          \n","          \n","          # transforma a un vector de nros\n","          arImag = np.array(imag)\n","          \n","          # agrega a los vectores\n","          classes_ori.append( each_dir )\n","          images_ori.append( arImag )\n","\n","print(\"- Clases cargadas: \", len(classes_ori))\n","print(\"- Imágenes cargadas: \", len(images_ori))\n","\n","if len(images_ori)>0:\n","  print(\"\\n- Ejemplo \", classes_ori[0], \" \", images_ori[0].shape, \": \")\n","  display( Image.fromarray(images_ori[0], tipoImage) )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eFpF2PNkSbjK","colab_type":"code","colab":{}},"source":["# define función auxiliar para mostrar imágenes preparadas\n","def plot_image(imag):\n","  if IMAGE_SHAPE[2]==1:\n","    plt.imshow((imag*255).reshape(IMAGE_SHAPE[0], IMAGE_SHAPE[1]).astype(np.uint8))\n","    plt.gray()\n","  else:\n","    plt.imshow((imag*255).reshape(IMAGE_SHAPE).astype(np.uint8))\n","  plt.axis(\"off\")  \n","\n","# define función auxiliar para preparar la lista de imágenes a procesar\n","def prepare_imageList(imagList):    \n","  auxiAr = np.array(imagList).astype('float32') / 255.\n","  auxiAr = auxiAr.reshape((len(auxiAr), num_inputs))  \n","  return auxiAr\n","\n","# define vector auxiliar para usar en el entrenamiento\n","x_train = prepare_imageList(images_ori)\n","\n","print(\"x_train (cant ejemplos, datos entrada): \", x_train.shape)\n","print(\"\\nImagen reconstruida: \")\n","plot_image(x_train[0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zOQAmtPAaqZg","colab_type":"text"},"source":["5) Creación del modelo DAE:"]},{"cell_type":"code","metadata":{"id":"LEwtvKsnJLBN","colab_type":"code","colab":{}},"source":["# define la arquitectura de capas del Deep Autoencoder\n","# teniendo en cuenta la definición dada anteriomente\n","input_img_Lay = Input(shape=(num_inputs,), name='input_img') # capa de entrada\n","eachLay = input_img_Lay\n","auxName = 'enc_'\n","auxId = 1 \n","for num_hid in dae_layers:  \n","\n","    # define el nombre de la capa oculta\n","    if num_features==num_hid:\n","        auxlayerName = 'features'\n","        auxName = 'dec_'\n","        auxId = auxId - 1\n","    else:\n","        auxlayerName = auxName+str(auxId)\n","        if auxName == 'enc_':\n","          auxId = auxId + 1\n","        else:\n","          auxId = auxId - 1\n","\n","    # agrega la capa oculta\n","    eachLay = Dense(num_hid, activation='relu', name=auxlayerName)(eachLay) # capas ocultas\n","\n","    if num_features==num_hid:\n","      features_Lay = eachLay\n","\n","output_img_Lay = Dense(num_outputs, activation=None, name='output_img')(eachLay) # capa de salida\n","\n","# genera el modelo Deep Autoencoder\n","DAEmodel = Model(input_img_Lay, output_img_Lay, name='DAE')\n","#DAEmodel.compile(optimizer='rmsprop', loss='mse', metrics=['accuracy'])\n","DAEmodel.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n","\n","print(\"Modelo DAE creado con \", len(DAEmodel.layers), \" capas:\")\n","DAEmodel.summary()\n","print(\"\\n\")\n","plot_model(DAEmodel, show_layer_names=True, show_shapes=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Nn7ynSDx0nLt","colab_type":"text"},"source":["5) Entrenar el modelo DAE:"]},{"cell_type":"code","metadata":{"id":"jmBH11GuJhk1","colab_type":"code","colab":{}},"source":["# lleva a cabo el entrenamiento\n","# usando los mismos datos como entrada y salida\n","DAEmodel.fit(x_train, x_train,\n","                epochs = cantEpocas, \n","                batch_size = 15)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8RhmI3R31Kzu","colab_type":"text"},"source":["7) Evaluar el modelo DAE entrenado solicitando que reconstruya las imágenes ingresadas:"]},{"cell_type":"code","metadata":{"id":"wfRff6b-LOxG","colab_type":"code","colab":{}},"source":["# evalua al modelo \n","resEval = DAEmodel.evaluate(x_train, x_train)\n","print(\"\\n>Evaluación del Modelo: \")\n","print(\"    - Error: \", resEval[0])\n","print(\"    - Exactitud: \", resEval[1]*100)\n","print(\"\\n\")\n","\n","# procesa las imágenes con el modelo \n","reconstr_imgs = DAEmodel.predict(x_train)\n","\n","# muestra las 15 primeras imágenes \n","print(\"\\n>Resultados: \")\n","for i in range(len(x_train)):\n","\n","    # prepara para mostrar\n","    fig = plt.figure()\n","    fig.suptitle(classes_ori[i])\n","\n","    # muestra la real\n","    ax1 = fig.add_subplot(121)\n","    plot_image(x_train[i])\n","\n","    # muestra la generada por el modelo\n","    ax2 = fig.add_subplot(122)\n","    plot_image(reconstr_imgs[i])\n","\n","    plt.tight_layout()\n","    fig = plt.gcf()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P0a79AY0r1Eo","colab_type":"text"},"source":["9) Probar el modelo DAE entrenado con otras imágenes:"]},{"cell_type":"code","metadata":{"id":"jTha04q2Hlsx","colab_type":"code","colab":{}},"source":["# función auxiliar para reconstruir la imagen\n","def reconstruct_image(imag, imagClase):\n","    \n","    # prepara y ajusta el tamaño de la imagen\n","    imagPrep = prepare_imageList([imag])\n","    \n","    # ejecuta el modelo\n","    imagOut = DAEmodel.predict(imagPrep)\n","    \n","    # prepara para mostrar\n","    fig = plt.figure()\n","    fig.suptitle(imagClase)\n","\n","    # muestra la real\n","    ax1 = fig.add_subplot(121)\n","    plot_image(imagPrep)\n","\n","    # muestra la generada por el modelo\n","    ax2 = fig.add_subplot(122)\n","    plot_image(imagOut)\n","\n","    plt.tight_layout()\n","    fig = plt.gcf()\n","\n","\n","# carga las imágenes de prueba\n","imagPathPrueba = path + '/IRIS/test' \n","all_dirs =  os.listdir( imagPathPrueba ) \n","for each_dir in all_dirs:\n","\n","    auxiPath = imagPathPrueba + '/' + each_dir \n","    if os.path.isdir(auxiPath):\n","      imagFN  = os.listdir( auxiPath )\n","      for each_imagFN in imagFN:\n","          \n","          # abre la imagen\n","          imag = Image.open(auxiPath + \"/\" + each_imagFN)\n","          \n","          # ajusta el tamaño\n","          if IMAGE_SHAPE[2]==1:\n","            imag = imag.convert('L')\n","          imag = imag.resize((IMAGE_SHAPE[0], IMAGE_SHAPE[1]), Image.ANTIALIAS)          \n","          \n","          # transforma a un vector de nros\n","          arImag = np.array(imag)\n","\n","          # manda a procesar la imagen cargada\n","          reconstruct_image(arImag, each_imagFN)\n","                  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YFl-ipxmHrok","colab_type":"text"},"source":["8) A partir del modelo DAE entrenado, generar dos sub-modelos Encoder y Decoder:"]},{"cell_type":"markdown","metadata":{"id":"eq6z-Gj5fttb","colab_type":"text"},"source":["\n","*   Generar y usar el modelo Encoder para 'clusterizar' las imágenes de entrenamiento:\n"]},{"cell_type":"code","metadata":{"id":"G6aAZfo2H3HW","colab_type":"code","colab":{}},"source":["## Generar el sub-modelo Encoder para Clustering\n","## (desde input hasta features)\n","\n","# reutiliza las capas entrenadas del modelo DAE original\n","clust_input_Lay = input_img_Lay  # capa de entrada\n","clust_output_Lay =  features_Lay  # capa de salida\n","\n","# genera el modelo\n","CLUSTmodel = Model(input_img_Lay, features_Lay, name='Encoder/Clustering')\n","\n","print(\"> Modelo Encoder: \")\n","CLUSTmodel.summary()\n","plot_model(CLUSTmodel, show_layer_names=True, show_shapes=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zGA6OetOfuX8","colab_type":"code","colab":{}},"source":["# función auxiliar para generar un gráfico \n","# con los valores codificados \n","# usando PCA para simplificarlos en 2 ejes\n","def genera_grafico_pca(datos, clases, titulo):\n","    pca = PCA(n_components=2)\n","    principalComponents = pca.fit_transform(datos)\n","    principalDf = pd.DataFrame(data = principalComponents,\n","                columns = ['pca_1', 'pca_2'])\n","    finalDf = pd.concat([principalDf, \n","                        pd.DataFrame(clases, columns = ['target'])], \n","                        axis = 1)\n","\n","    fig = plt.figure(figsize = (10,10))\n","    ax = fig.add_subplot(1,1,1) \n","    ax.set_xlabel('PCA1', fontsize = 15)\n","    ax.set_ylabel('PCA2', fontsize = 15)\n","    ax.set_title(titulo, fontsize = 20)\n","    for target in set(classes_ori):\n","        indicesToKeep = finalDf['target'] == target\n","        ax.scatter(finalDf.loc[indicesToKeep, 'pca_2'],\n","                  finalDf.loc[indicesToKeep, 'pca_1'],\n","                  s = 50)\n","    ax.legend(set(classes_ori))\n","    ax.grid()\n","\n","# procesa las imágenes para recibir el valor codificado de cada una\n","x_train_encoded = CLUSTmodel.predict(x_train)\n","\n","# muestra el gráfico con imágenes originales\n","genera_grafico_pca(x_train, classes_ori, \"Representación de Imágenes Originales\")\n","\n","# muestra estadísticas de los datos codificados\n","minArClust = np.empty(num_features)\n","minArClust.fill(9999.99)\n","maxArClust = np.empty(num_features)\n","maxArClust.fill(-9999.99)\n","sumArClust = np.zeros(num_features)\n","for val in x_train_encoded:\n","  for i in range(num_features):\n","      sumArClust[i] = sumArClust[i]+val[i]\n","      if val[i]<minArClust[i]: \n","          minArClust[i] = val[i]\n","      if val[i]>maxArClust[i]: \n","          maxArClust[i] = val[i]\n","print(\"\\n\\n> Estadísticas de Clutering de Imágenes codificado en \", num_features,\" valores: \")\n","print(\"- Mínimos:   \", minArClust)\n","print(\"- Máximos:   \", maxArClust)\n","print(\"- Totales:   \", sumArClust)\n","print(\"- Promedios: \", sumArClust/len(x_train_encoded))\n","print(\"\\n\\n\")\n","\n","# muestra el gráfico codificado\n","genera_grafico_pca(x_train_encoded, classes_ori, \"Representación de Clustering de Imágenes\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j_4UqnQtg1hP","colab_type":"text"},"source":["*   Generar y usar el modelo Decoder para generar nuevas imágenes similares a las entrenadas:"]},{"cell_type":"code","metadata":{"id":"PHueHIOYOaBg","colab_type":"code","colab":{}},"source":["## Generar el sub-modelo Decoder para Generator\n","## (desde features hasta output)\n","\n","# genera una copia del modelo DAE original para evitar romperlo\n","auxiCloneModel = keras.models.model_from_json(DAEmodel.to_json())\n","#auxiCloneModel.summary()\n","\n","# genera la nueva estructura del Generator\n","input_gen = Input(shape=(num_features,), name='input_gen') # nueva capa de entrada\n","auxLay_gen = input_gen\n","for pos in range(len(DAEmodel.layers)):\n","\n","  # obtiene el nombre de la capa actual\n","  auxName = DAEmodel.layers[pos].name  \n","  \n","  # sólo considera las capas luego de features (decoder y output)\n","  # para copiar los pesos del DAE original y actualizar la estrcutura\n","  if auxName.startswith('dec_') or auxName=='output_img':\n","    auxiCloneModel.layers[pos].set_weights(DAEmodel.layers[pos].get_weights()) \n","    auxLay_gen = auxiCloneModel.layers[pos](auxLay_gen) \n","\n","# crea el nuevo modelo Generator\n","GENmodel = Model(input_gen, auxLay_gen, name = 'Decoder/Generator')\n","\n","print(\"> Modelo Decoder: \")\n","GENmodel.summary()\n","plot_model(GENmodel, show_layer_names=True, show_shapes=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"54A8l5l9St3c","colab_type":"code","colab":{}},"source":["# ejecuta el Generator\n","#  usando valores definidos al azar como datos de entrada\n","\n","cantImagenGenerar = 3\n","consideraEstadClust = True\n","\n","# genera los datos de entrada\n","# (como la codificación tiene varias posiciones con ceros \n","# se considera que sólo se ponen al azar entre 10% y el 70% de los valores, el resto queda en cero,\n","# --sino se podría hacer con \" np.random.rand(cantImagenGenerar, num_features) \"-- )\n","arX = []\n","if consideraEstadClust:\n","    # si están definidas las estadísticas de clustering,\n","    # genera los valores considerandolas\n","    print(\"Genera usando estadísticas de Clustering\")\n","    for i in range(cantImagenGenerar):\n","        X = np.zeros(num_features)\n","        for pos in range(num_features):\n","            if sumArClust[pos]>0:\n","                X[pos] = np.random.uniform(minArClust[pos],maxArClust[pos])\n","        arX.append( X )\n","else:\n","      # si no están definidas las estadísticas de clustering,\n","    # genera los valores totalmente al azar\n","    print(\"Genera usando valores al azar\")\n","    minRnd = num_features*10//100\n","    maxRnd = num_features*70//100\n","    for i in range(cantImagenGenerar):\n","        X = np.zeros(num_features)\n","        for j in range(np.random.randint(low=minRnd, high=maxRnd)):\n","            pos = np.random.randint(low=0, high=num_features-1)\n","            X[pos] = np.random.normal()\n","        arX.append( X )\n","\n","\n","# ejecuta el modelo Generator\n","imagOut = GENmodel.predict( np.array(arX).reshape((len(arX), num_features)) )  \n"," \n","# muestra las imágenes generadas\n","print(\"\\n> Resultados: \")\n","for i in range(len(arX)):\n","\n","    fig = plt.figure()\n","\n","    # muestra los datos\n","    ax1 = fig.add_subplot(121)\n","    datosMostrar = arX[i].reshape(num_features, 1) \n","    ax1.table(cellText=datosMostrar, loc='center')   \n","    ax1.get_xaxis().set_visible(False)\n","    ax1.get_yaxis().set_visible(False)  \n","\n","    #  muestra reconstrucción\n","    ax2 = fig.add_subplot(122)\n","    plot_image(imagOut[i])  \n","\n","    plt.tight_layout()\n","    fig = plt.gcf()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u19qkoTn3U8-","colab_type":"text"},"source":["*   Combinar los resultados de los modelos Clustering y Generator para mostrar que funcionan juntos como el DAE original:"]},{"cell_type":"code","metadata":{"id":"ubf2Yo3J1aEF","colab_type":"code","colab":{}},"source":["# prueba el modelo Generator usando como entrada los datos de Clustering\n","pruebaClust = CLUSTmodel.predict( x_train )\n","pruebaClust_out = GENmodel.predict(  np.array(pruebaClust).reshape((len(pruebaClust), num_features)) )  \n"," \n","# muestra las imágenes generadas\n","print(\"\\n> Resultados (valores de clustering, imagen recounstrida(grande) y original(chica): \")\n","for i in range(len(x_train_encoded)):\n","\n","    fig = plt.figure()\n","\n","    # muestra los datos\n","    ax1 = fig.add_subplot(121)\n","    ax1.table(cellText=pruebaClust[i].reshape(num_features, 1), loc='center')   \n","    ax1.get_xaxis().set_visible(False)\n","    ax1.get_yaxis().set_visible(False)  \n","\n","    #  muestra reconstrucción\n","    ax2 = fig.add_subplot(122)\n","    plot_image(pruebaClust_out[i])  \n","\n","    # muestra imagen original\n","    ax3 = fig.add_subplot(332)\n","    plot_image(x_train[i])  \n","\n","    fig = plt.gcf()\n"],"execution_count":null,"outputs":[]}]}