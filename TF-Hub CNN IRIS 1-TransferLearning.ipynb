{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TF-Hub CNN IRIS 1-TransferLearning.ipynb","provenance":[{"file_id":"1sr2CvIzfyuBJoRZBC7XEUExL9w0RKzSY","timestamp":1580297616360}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"r6X3sZdb3I7T","colab_type":"text"},"source":["# Demo de 'Transfer Learning con TF-Hub' en el cual se logra un modelo que puede aprender a reconocer los Tipos de Flores Iris usando como base un modelo ya entrenado para reconocer otros tipos de objetos\n","Basado en https://www.tensorflow.org/tutorials/images/transfer_learning_with_hub"]},{"cell_type":"markdown","metadata":{"id":"uWXyQCDm4w8Q","colab_type":"text"},"source":["0) Instalar el paquete:"]},{"cell_type":"code","metadata":{"id":"nDUNgn2e3R57","colab_type":"code","colab":{}},"source":["# Luego de instalar el paquete tal vez necesario reiniciar el entorno (ver mensajes que genera)\n","try:\n","  # %tensorflow_version only exists in Colab.\n","  !pip install -q tf-nightly\n","except Exception:\n","  pass\n","\n","!pip install -q -U tf-hub-nightly\n","!pip install -q tfds-nightly"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZQ3UDqAY4zlD","colab_type":"text"},"source":["1) Importar librerías:"]},{"cell_type":"code","metadata":{"id":"NafdiEwq3IMh","colab_type":"code","colab":{}},"source":["# For running inference on the TF-Hub module.\n","import tensorflow as tf\n","\n","import tensorflow_hub as hub\n","\n","# For downloading the image.\n","from __future__ import absolute_import, division, print_function, unicode_literals\n","import matplotlib.pylab as plt\n","from tensorflow.keras import layers\n","\n","import numpy as np\n","import PIL.Image as Image\n","import csv\n","\n","print(\"\\nLibrerías importadas\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wQgrCk0A5K-Y","colab_type":"text"},"source":["2) Cargar el modelo a utilizar para procesar:"]},{"cell_type":"code","metadata":{"id":"w3gENv7QReSr","colab_type":"code","colab":{}},"source":["# selección del modelo a usar de base\n","#modeloUsar = 'mobilenet_v2'\n","modeloUsar = 'inception_v3'\n","\n","print(\"\\nModelo \", modeloUsar, \"seleccionado\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KfAEfS_Y3eL_","colab_type":"code","colab":{}},"source":["# define configuración del modelo\n","if modeloUsar == 'inception_v3':\n","\n","    # URLs donde se encuentra la info del modelo Inception v3\n","    classifier_url =\"https://tfhub.dev/google/tf2-preview/inception_v3/classification/4\" \n","    feature_extractor_url = \"https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/4\"\n","\n","    # define el tamaño de imágenes soportadas del modelo Inception v3\n","    IMAGE_SHAPE = (299, 299)\n","else:\n","\n","    # URLs donde se encuentra la info del modelo mobileNet\n","    classifier_url =\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\" \n","    feature_extractor_url = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n","\n","    # define el tamaño de imágenes soportadas del modelo mobileNet\n","    IMAGE_SHAPE = (224, 224)\n","\n","# carga el módulo a usar\n","classifier = tf.keras.Sequential([ hub.KerasLayer(classifier_url, input_shape=IMAGE_SHAPE+(3,)) ])\n","\n","# baja la lista de clases originales que maneja el modelo (inception o mobilenet)\n","model_labels_path = tf.keras.utils.get_file('ImageNetLabels.txt',\n","                                            'https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')\n","model_imagenet_labels = np.array(open(model_labels_path).read().splitlines())\n","\n","print(\"\\nModelo \", modeloUsar, \"cargado\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pgMOT8WvGWMB","colab_type":"text"},"source":["3) Montar el Drive:"]},{"cell_type":"code","metadata":{"id":"0pkkaUToGKc7","colab_type":"code","colab":{}},"source":["import os\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","\n","# directorio local en Google Drive\n","path = 'gdrive/My Drive/IA/demo IRIS' \n","model_export_path = path + '/Model_TFHub'\n","imagPath = path + '/IRIS/train'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tMbKRc0E5ONE","colab_type":"text"},"source":["4) Cargar imágenes para re-entrenar:"]},{"cell_type":"code","metadata":{"id":"GE_3cMSTyzfG","colab_type":"code","colab":{}},"source":["# carga y aplica DataAugmentation \n","# (los nombres de las clases son los nombres de los directorios)\n","image_generator =  tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255,\n","                                                                   shear_range = 0.2,\n","                                                                   zoom_range = 0.2,\n","                                                                   horizontal_flip = False)\n","\n","print(\"Imágenes: \")\n","image_data = image_generator.flow_from_directory(str(imagPath), \n","                                                 target_size=IMAGE_SHAPE,\n","                                                 class_mode=\"categorical\",\n","                                                 shuffle=True)\n","for image_batch, label_batch in image_data:\n","  print(\"Image batch shape: \", image_batch.shape)\n","  print(\"Label batch shape: \", label_batch.shape)\n","  break\n","\n","  # define los nombres de las clases\n","dic_class_names = sorted(image_data.class_indices.items(), key=lambda pair:pair[1])\n","class_names = np.array([key.title() for key, value in dic_class_names])\n","print(\"\\nClases: \", class_names)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DLlvyl7t0aGy","colab_type":"text"},"source":["5) Probar resultados del modelo antes de entrenar ejecutando el modelo sobre las imágenes cargadas:"]},{"cell_type":"code","metadata":{"id":"7gLWIWI50bn2","colab_type":"code","colab":{}},"source":["# ejecuta el modelo\n","result_batch = classifier.predict(image_batch)\n","\n","# determina resultados\n","predicted_class_names = model_imagenet_labels[np.argmax(result_batch, axis=-1)]\n","\n","# muestra resultados\n","plt.figure(figsize=(10,19))\n","plt.subplots_adjust(hspace=0.4)\n","col = 3\n","rows=len(image_batch)//col\n","\n","_ = plt.suptitle(\"Predicciones del Modelo Original\")\n","for n in range(col*rows):\n","  plt.subplot(rows,col,n+1)\n","  plt.imshow(image_batch[n])\n","  plt.title(predicted_class_names[n])\n","  plt.axis('off')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Nn7ynSDx0nLt","colab_type":"text"},"source":["6) Re-entrenar el modelo:"]},{"cell_type":"code","metadata":{"id":"rsC_kbKZ0pO-","colab_type":"code","colab":{}},"source":["# Obtiene el modeo base del modelo para usar en el re-entrenamiento, congelandolo\n","# y agregandole una nueva capa para aprender las nuevas clases\n","\n","# Create the feature extractor\n","feature_extractor_layer = hub.KerasLayer(feature_extractor_url,\n","                                         input_shape=IMAGE_SHAPE+(3,))\n","\n","# It returns a 1280-length vector for each image:\n","feature_batch = feature_extractor_layer(image_batch)\n","print(feature_batch.shape)\n","\n","# Freeze the variables in the feature extractor layer, so that the training only modifies the new classifier layer.\n","feature_extractor_layer.trainable = False\n","\n","# Attach a classification head\n","model = tf.keras.Sequential([ feature_extractor_layer, \n","                             layers.Dense(image_data.num_classes, activation='softmax') ])\n","\n","# Use compile to configure the training process\n","model.compile(\n","  optimizer=tf.keras.optimizers.Adam(),\n","  loss='categorical_crossentropy',\n","  metrics=['acc'] )\n","\n","# nuevo modelo a re-entrenar\n","print(\"\\n\")\n","model.summary()\n","\n","# info de imágenes a aprender\n","print(\"\\n\")\n","predictions = model(image_batch)\n","predictions.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rJrs3DFO1IzN","colab_type":"code","colab":{}},"source":["# ejecuta el re-entrenamiento del modelo\n","\n","# functions to visualize the training progress\n","class CollectBatchStats(tf.keras.callbacks.Callback):\n","  def __init__(self):\n","    self.batch_losses = []\n","    self.batch_acc = []\n","\n","  def on_train_batch_end(self, batch, logs=None):\n","    self.batch_losses.append(logs['loss'])\n","    self.batch_acc.append(logs['acc'])\n","    self.model.reset_metrics()\n","\n","# ejecuta el entrenamiento\n","steps_per_epoch = np.ceil(image_data.samples/image_data.batch_size)\n","\n","batch_stats_callback = CollectBatchStats()\n","\n","history = model.fit_generator(image_data, epochs=35,\n","                              steps_per_epoch=steps_per_epoch,\n","                              callbacks = [batch_stats_callback])\n","\n","print(\"\\nModelo re-entrenado\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vwWjxqQp1Nnp","colab_type":"code","colab":{}},"source":["# muestra gráficos con resultados del re-entrenamiento\n","plt.figure()\n","plt.ylabel(\"Perdida\")\n","plt.xlabel(\"Pasos de Entrenamiento\")\n","plt.ylim([0,2])\n","plt.plot(batch_stats_callback.batch_losses)\n","\n","plt.figure()\n","plt.ylabel(\"Exactitud\")\n","plt.xlabel(\"Pasos de Entrenamiento\")\n","plt.ylim([0,1])\n","plt.plot(batch_stats_callback.batch_acc)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8RhmI3R31Kzu","colab_type":"text"},"source":["7) Probar nuevo modelo re-entrenado:"]},{"cell_type":"code","metadata":{"id":"jRUZYx671RVY","colab_type":"code","colab":{}},"source":["# ejecuta el modelo re-entrenado\n","predicted_batch = model.predict(image_batch)\n","predicted_id = np.argmax(predicted_batch, axis=-1)\n","label_id = np.argmax(label_batch, axis=-1)\n","\n","# muestra resultados\n","plt.figure(figsize=(10,19))\n","plt.subplots_adjust(hspace=0.4)\n","col = 3\n","rows = len(image_batch)//col\n","\n","for n in range(col*rows):\n","  plt.subplot(rows,col,n+1)\n","  plt.imshow(image_batch[n])\n","  if  predicted_id[n] == label_id[n]:\n","    color = \"green\"  \n","    res = class_names[predicted_id[n]]\n","  else:\n","    color = \"red\"\n","    res = class_names[predicted_id[n]] + ' [real ' + class_names[label_id[n]] + ']' \n","\n","  plt.title(res, color=color)\n","  plt.axis('off')\n","_ = plt.suptitle('Predicciones del Modelo ' + modeloUsar + ' Re-Entrenado (verde ok, rojo error)')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"useDL95J1Ypo","colab_type":"text"},"source":["8) Grabar el modelo re-entrenado:"]},{"cell_type":"code","metadata":{"id":"ViUYOJPi1ab2","colab_type":"code","colab":{}},"source":["# exporta modelo reentrenado\n","model.save(model_export_path, save_format='tf')\n","print(\"\\nModelo grabado en \", model_export_path)\n","\n","# exporta definición de tamaño de imágenes\n","with open( model_export_path + '/imagshape.csv', mode='w') as csvfile:\n","    wr = csv.writer(csvfile)\n","    wr.writerow(IMAGE_SHAPE)\n","\n","# exporta definición de las clases\n","with open( model_export_path + '/clases.csv', mode='w') as csvfile:\n","    wr = csv.writer(csvfile)\n","    wr.writerow(class_names)\n","print('Definición de las clases: ', class_names, ' grabada')"],"execution_count":null,"outputs":[]}]}